{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Twitter Sentiment Analysis in Python Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Necesary Data Structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Natural Language Processing libraries\n",
    "from wordcloud import WordCloud\n",
    "from nltk import TweetTokenizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "# Machine Learning Tools\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Quick settings before starting\n",
    "%matplotlib inline\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the training dataset as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2014351367</td>\n",
       "      <td>Wed Jun 03 01:14:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cathyleehart</td>\n",
       "      <td>@just_tam21 hahah its kind of the same as adel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1984531826</td>\n",
       "      <td>Sun May 31 15:17:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>carlawaslike</td>\n",
       "      <td>@Austinjamest sweeeet can't wait to go there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2185079853</td>\n",
       "      <td>Mon Jun 15 16:51:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Rommellll</td>\n",
       "      <td>You said you changed how wrong i proved you  n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1998128979</td>\n",
       "      <td>Mon Jun 01 18:02:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pauljopling</td>\n",
       "      <td>I can't wait for New Moon after seeing the tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2182994010</td>\n",
       "      <td>Mon Jun 15 13:54:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thisgoodlife</td>\n",
       "      <td>@nicolassa new drum carder? SWEET!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment          id                          Date     Query  \\\n",
       "0          4  2014351367  Wed Jun 03 01:14:33 PDT 2009  NO_QUERY   \n",
       "1          4  1984531826  Sun May 31 15:17:28 PDT 2009  NO_QUERY   \n",
       "2          4  2185079853  Mon Jun 15 16:51:18 PDT 2009  NO_QUERY   \n",
       "3          4  1998128979  Mon Jun 01 18:02:23 PDT 2009  NO_QUERY   \n",
       "4          4  2182994010  Mon Jun 15 13:54:26 PDT 2009  NO_QUERY   \n",
       "\n",
       "           User                                              Tweet  \n",
       "0  cathyleehart  @just_tam21 hahah its kind of the same as adel...  \n",
       "1  carlawaslike  @Austinjamest sweeeet can't wait to go there w...  \n",
       "2     Rommellll  You said you changed how wrong i proved you  n...  \n",
       "3   pauljopling  I can't wait for New Moon after seeing the tra...  \n",
       "4  thisgoodlife                @nicolassa new drum carder? SWEET!   "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train_dataset_20k.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By default, sentiments are labeled as \"4\" for positive and \"0\" for negative. For legibility purposes, I'm adjusting the training dataset by replacing the 4's with 1's, and also by getting rid of unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014351367</td>\n",
       "      <td>@just_tam21 hahah its kind of the same as adel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1984531826</td>\n",
       "      <td>@Austinjamest sweeeet can't wait to go there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2185079853</td>\n",
       "      <td>You said you changed how wrong i proved you  n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1998128979</td>\n",
       "      <td>I can't wait for New Moon after seeing the tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2182994010</td>\n",
       "      <td>@nicolassa new drum carder? SWEET!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment          id                                              Tweet\n",
       "0          1  2014351367  @just_tam21 hahah its kind of the same as adel...\n",
       "1          1  1984531826  @Austinjamest sweeeet can't wait to go there w...\n",
       "2          1  2185079853  You said you changed how wrong i proved you  n...\n",
       "3          1  1998128979  I can't wait for New Moon after seeing the tra...\n",
       "4          1  2182994010                @nicolassa new drum carder? SWEET! "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[[\"Sentiment\", \"id\", \"Tweet\"]]\n",
    "df_train.replace(4, 1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentiment  20000 non-null  int64 \n",
      " 1   id         20000 non-null  int64 \n",
      " 2   Tweet      20000 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 468.9+ KB\n",
      "\n",
      "There are 20,000 rows and 3 columns in our Tweet Training Set.\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "print(f\"\\nThere are {df_train.shape[0]:,} rows and {df_train.shape[1]:,} columns in our Tweet Training Set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To preprocess the tweets in our training dataset, we must do the following:\n",
    " 1. Remove hyperlinks, punctuation, and hashtags\n",
    " 2. Transform each Tweet into a list of its individual words\n",
    " 3. Convert each word to Lower Case\n",
    " 4. Delete stop words\n",
    " 5. Stemming to equate words like \"eat\", \"eats\", and \"eating\" all to \"eat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(df):\n",
    "    \"\"\"\n",
    "    The preprocess_tweets() function goes through the following steps:\n",
    "        1. Remove hyperlinks, punctuation, and hashtags\n",
    "        2. Transform each Tweet into a list of its individual words\n",
    "        3. Convert each word to Lower Case\n",
    "        4. Delete stop words\n",
    "        5. Stemming to equate words like \"eat\", \"eats\", and \"eating\" all to \"eat\"\n",
    "\n",
    "    params:\n",
    "        df : Pandas Dataframe containing our data\n",
    "\n",
    "    @RETURN a 2D Python list with columns representing individual words and rows representing\n",
    "        each individual Tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace certain characters in each Tweet with empty spaces instead\n",
    "    df[\"Tweet\"] = df[\"Tweet\"].str.replace(r\"\\$\\w*\", \"\", regex=True)\n",
    "    df[\"Tweet\"] = df[\"Tweet\"].str.replace(r\"https?:\\/\\/.*[\\r\\n]:\", \"\", regex=True)\n",
    "    df[\"Tweet\"] = df[\"Tweet\"].str.replace(r\"http?:\\/\\/.*[\\r\\n]:\", \"\", regex=True)\n",
    "    df[\"Tweet\"] = df[\"Tweet\"].str.replace(r\"#\", \"\", regex=True)\n",
    "\n",
    "    # Initialize a Tweet Tokenizer method that will convert Tweets to lower-case and eliminate Twitter handles\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "    # Make necessary declarations for upcoming 2D for-loop\n",
    "    n = df.shape[0]\n",
    "    tokens = []\n",
    "    stopWords = stopwords.words(\"english\")\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmedTweets = []\n",
    "\n",
    "    # Tokenize our tweets and insert them into the tokens numpy array\n",
    "    for i in range(n):\n",
    "        buffer = []\n",
    "        tokens.append(tokenizer.tokenize(df_train.loc[i, \"Tweet\"]))\n",
    "\n",
    "        # Remove stop words and words with punctuation \n",
    "        for tweet_word in tokens[i]:\n",
    "            if tweet_word not in stopWords and tweet_word not in string.punctuation:\n",
    "                #buffer.append(tweet_word)\n",
    "                stem_word = stemmer.stem(str(tweet_word))\n",
    "                buffer.append(stem_word)\n",
    "            \n",
    "        # Append the 2D List that we'll be returning with this function\n",
    "        stemmedTweets.append(buffer)\n",
    "        \n",
    "\n",
    "    return stemmedTweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the preprocess_tweets() function to return a 2D List containing cleaned tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingTweets = preprocess_tweets(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a y-vector that includes all of the true positive and negative classifications for our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(df_train.shape[0]):\n",
    "    y_train.append(1 if df_train[\"Sentiment\"][i] == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary including all of our words and their positive and negative appearance frequencies in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the dictionary Data Structure every time the for loop comes across a new word, and update\n",
    "# it by either incrementing the positive index [0] or negative index [1], depending on what kind\n",
    "# of tweet it pops up in\n",
    "dictionary = {}\n",
    "for y, tweet in zip(y_train, trainingTweets):\n",
    "    for token in tweet:\n",
    "        if token not in dictionary:\n",
    "            dictionary[token] = [1,0] if y==0 else [0,1]\n",
    "        elif token in dictionary:\n",
    "            if y==0:\n",
    "                dictionary[token][0] += 1\n",
    "            elif y==1:\n",
    "                dictionary[token][1] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Positive appearances and Negative appearance lists for training tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "posTrainingTweets = [[trainingTweets[i] for i in range(len(trainingTweets)) if y_train[i]==1 ]]\n",
    "negTrainingTweets = [[trainingTweets[i] for i in range(len(trainingTweets)) if y_train[i]==0 ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction: Create a (tweetNum) x 3 matrix to represent the following:\n",
    "#### col[0] : all 1's to take into account a constant in a logistic regression model\n",
    "#### col[1] : the number of training-set positive appearances for each word in each tweet\n",
    "#### col[2] : the number of training-set negative appearances for each word in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_data(tweets, y, dictionary=dictionary):\n",
    "    \"\"\"\n",
    "    The numerical_data() function translates tweets to measurable, quantitative data in a 2D matrix\n",
    "    representing the following:\n",
    "        column[0] : all 1's to denote where the logistic regression model stands in an empty\n",
    "                    tweet\n",
    "        column[1] : the sum of all positive appearances in the entire training set of each word that's\n",
    "                    located in the tweet being evaluated\n",
    "        column[2] : the sum of all negative appearances in the entire training set of each word that's\n",
    "                    located in the tweet being evaluated\n",
    "    \n",
    "    params:\n",
    "        tweets : a 2D-list where the outer elements represent individual tweets and the inner elements \n",
    "                 represent individual words within the tweet\n",
    "        y : a list denoting the true sentiment score (1 or 0) of each tweet\n",
    "        dictionary : a dict-type data structure representing all the words that appear in the training set,\n",
    "                     as well as their total positive and negative appearances within the training set\n",
    "\n",
    "    @RETURN a mx3 matrix where m represents the total number of tweets\n",
    "    \"\"\"\n",
    "    m = len(tweets)\n",
    "    X = np.zeros((m, 3))\n",
    "\n",
    "    for i in range(m):\n",
    "        X[i][0] = 1\n",
    "        for word in tweets[i]:\n",
    "            if word in dictionary:\n",
    "                X[i][1] += dictionary[word][0]\n",
    "                X[i][2] += dictionary[word][1]\n",
    "\n",
    "    return X\n",
    "\n",
    "    # m = len(tweets)\n",
    "    # X = np.zeros((m, 3))\n",
    "\n",
    "    # for i in range(m):\n",
    "    #     X[i][0] = 1\n",
    "    #     for word in tweets[i]:\n",
    "    #         if word in dictionary:\n",
    "    #             if dictionary[word][0] > dictionary[word][1]:\n",
    "    #                 X[i][1] += 1\n",
    "    #             elif dictionary[word][0] < dictionary[word][1]:\n",
    "    #                 X[i][2] += 1\n",
    "\n",
    "    # return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = numerical_data(trainingTweets, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scikit-learn to generate logistic regression parameters, and test our model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training accuracy is 69.25%\n"
     ]
    }
   ],
   "source": [
    "# Create a LogisticRegression() object\n",
    "logReg = LogisticRegression()\n",
    "\n",
    "# Fit logistic regression parameters\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "# Calculate training accuracy and output it\n",
    "trainingAccuracy = logReg.score(X_train, y_train)\n",
    "print(f\"Our training accuracy is {trainingAccuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a Gradient Descent function to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44725e87ea676ad54a1d04bd571a955ef3e1f81ad317abec2d67776713178d01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
